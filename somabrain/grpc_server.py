"""Minimal gRPC server for the SomaBrain memory service.

The protobuf definition lives in ``somabrain/proto/memory.proto`` and is
compiled with ``grpcio-tools``.  This server implements the two RPCs defined in
the ``MemoryService`` service: ``Remember`` and ``Recall``.  In a real
deployment the implementation would forward the request to the external memory
service (or to the existing HTTP endpoint).  For the purpose of early testing we
simply acknowledge ``Remember`` and return an empty list for ``Recall``.

Running this module directly starts a gRPC server on port **50052** (the port
required by the compliance roadmap).  The Dockerfile and Helm chart later
reference this entry‑point.
"""

from __future__ import annotations

import logging
from concurrent import futures
from typing import Optional, Tuple

import grpc

# Import the generated protobuf classes.  They will be generated by running:
# ``python -m grpc_tools.protoc -I./somabrain/proto --python_out=./somabrain/proto --grpc_python_out=./somabrain/proto ./somabrain/proto/memory.proto``
from .proto import memory_pb2, memory_pb2_grpc
import json

from .memory_client import MemoryClient
from .stub_audit import StubUsageError
import uuid

try:  # Optional dependency during early consolidation
    from common.config.settings import settings as shared_settings
except Exception:  # pragma: no cover - maintain backwards compatibility
    shared_settings = None  # type: ignore

LOGGER = logging.getLogger(__name__)


class MemoryService(memory_pb2_grpc.MemoryServiceServicer):
    """gRPC MemoryService that forwards requests to the HTTP MemoryClient.

    This implementation uses the central `MemoryClient` (HTTP-first) so the
    gRPC server acts as a thin transport layer. Errors from the client are
    propagated as gRPC UNAVAILABLE status when appropriate.
    """

    def __init__(self, mem_client: MemoryClient):
        self._mem = mem_client

    def Remember(self, request: memory_pb2.RememberRequest, context: grpc.ServicerContext) -> memory_pb2.RememberResponse:  # noqa: D401
        LOGGER.debug("Received Remember request: %s", request)
        try:
            payload = {}
            if hasattr(request, "payload") and request.payload is not None:
                # Map protobuf MemoryPayload -> dict expected by MemoryClient
                payload["content"] = getattr(request.payload, "content", "")
                try:
                    # allow callers to pass JSON in content; keep as raw string otherwise
                    payload_json = json.loads(payload["content"]) if payload["content"] else None
                    if isinstance(payload_json, dict):
                        payload.update(payload_json)
                except Exception:
                    # leave content as-is
                    pass
                if getattr(request.payload, "quality_score", None) is not None:
                    payload["quality_score"] = float(request.payload.quality_score)
            coord_key = getattr(request.payload, "coord_key", "") or str(uuid.uuid4())
            # Call sync remember (MemoryClient handles async scheduling internally)
            self._mem.remember(coord_key, payload)
            return memory_pb2.RememberResponse(ok=True)
        except StubUsageError as e:
            # Stub usage in strict mode – surface as UNAVAILABLE with clear message
            LOGGER.error("Strict mode stub usage in Remember: %s", e)
            context.set_details(str(e))
            context.set_code(grpc.StatusCode.UNAVAILABLE)
            return memory_pb2.RememberResponse(ok=False)
        except Exception as e:
            LOGGER.exception("Remember failed: %s", e)
            context.set_details(str(e))
            context.set_code(grpc.StatusCode.UNAVAILABLE)
            return memory_pb2.RememberResponse(ok=False)

    def Recall(self, request: memory_pb2.RecallRequest, context: grpc.ServicerContext) -> memory_pb2.RecallResponse:  # noqa: D401
        LOGGER.debug("Received Recall request: query=%s top_k=%s", request.query, request.top_k)
        try:
            hits = self._mem.recall(request.query or "", top_k=int(request.top_k or 3))
            items = []
            for h in hits:
                payload = h.payload if hasattr(h, "payload") and h.payload is not None else {}
                coord_key = payload.get("id") or payload.get("memory_id") or ""
                try:
                    content = json.dumps(payload, default=str)
                except Exception:
                    content = str(payload)
                score = float(h.score) if getattr(h, "score", None) is not None else 0.0
                items.append(memory_pb2.RecallItem(coord_key=str(coord_key), content=content, quality_score=score))
            return memory_pb2.RecallResponse(items=items)
        except StubUsageError as e:
            LOGGER.error("Strict mode stub usage in Recall: %s", e)
            context.set_details(str(e))
            context.set_code(grpc.StatusCode.UNAVAILABLE)
            return memory_pb2.RecallResponse(items=[])
        except Exception as e:
            LOGGER.exception("Recall failed: %s", e)
            context.set_details(str(e))
            context.set_code(grpc.StatusCode.UNAVAILABLE)
            return memory_pb2.RecallResponse(items=[])


def _resolve_port(default: int = 50052) -> int:
    """Resolve the listen port from shared settings or fall back to ``default``."""

    if shared_settings is not None:
        try:
            candidate = getattr(shared_settings, "memory_grpc_port", None)
            if candidate is not None:
                return int(candidate)
        except Exception:
            pass
    try:
        from os import getenv

        env_value = getenv("SOMABRAIN_MEMORY_GRPC_PORT")
        if env_value:
            return int(env_value)
    except Exception:
        pass
    return default


def create_server(
    *,
    port: Optional[int] = None,
    max_workers: int = 8,
    memory_client: Optional[MemoryClient] = None,
) -> Tuple[grpc.Server, int]:
    """Create a configured gRPC server instance without starting it.

    Parameters
    ----------
    port:
        Overrides the default listen port (50052). When ``None`` we attempt to
        resolve the port from shared settings / environment variables so that
        deployment manifests only need to change a single source of truth.
    max_workers:
        Size of the worker pool handed to ``grpc.server``. High-throughput
        deployments set this to match CPU availability.
    memory_client:
        Pre-configured ``MemoryClient``. When omitted we instantiate one using
        ``somabrain.config.get_config`` so the server mirrors the behaviour of
        the HTTP API.
    """

    if memory_client is None:
        try:
            from .config import get_config

            cfg = get_config()
        except Exception:
            cfg = None
        if cfg is None:
            from somabrain.config import get_config as _get_cfg

            cfg = _get_cfg()
        memory_client = MemoryClient(cfg)

    listen_port = port if port is not None else _resolve_port()
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))
    memory_pb2_grpc.add_MemoryServiceServicer_to_server(
        MemoryService(memory_client), server
    )
    server.add_insecure_port(f"[::]:{listen_port}")
    return server, listen_port


def serve(
    *,
    port: Optional[int] = None,
    max_workers: int = 8,
    memory_client: Optional[MemoryClient] = None,
) -> None:
    """Start the gRPC memory service and block until termination."""

    server, listen_port = create_server(
        port=port, max_workers=max_workers, memory_client=memory_client
    )
    LOGGER.info("Starting SomaBrain gRPC MemoryService on port %s", listen_port)
    server.start()
    server.wait_for_termination()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    serve()
