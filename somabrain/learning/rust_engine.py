"""
Rust Adaptation Engine Bridge.

Provides transparent fallback: uses Rust AdaptationEngine when available,
falls back to pure Python implementation when not.

ALL 10 PERSONAS - VIBE Coding Rules:
- ðŸ›ï¸ Architect: Clean bridge pattern
- ðŸ Django: Python fallback
- ðŸ¦€ Rust: High-performance CPU-bound operations
- ðŸ§ª QA: Both paths tested
"""

from __future__ import annotations

import logging
from typing import Tuple

logger = logging.getLogger(__name__)

# Try to import Rust implementation
try:
    from somabrain_rs import AdaptationEngine as RustAdaptationEngine
    from somabrain_rs import RetrievalWeights as RustRetrievalWeights
    from somabrain_rs import UtilityWeights as RustUtilityWeights

    RUST_ADAPTATION_AVAILABLE = True
    logger.info("âœ… Rust AdaptationEngine loaded - using high-performance backend")
except ImportError:
    RUST_ADAPTATION_AVAILABLE = False
    RustAdaptationEngine = None
    RustRetrievalWeights = None
    RustUtilityWeights = None
    logger.warning("âš ï¸ Rust AdaptationEngine not available - using Python fallback")


def is_rust_adaptation_available() -> bool:
    """Check if Rust adaptation engine is available."""
    return RUST_ADAPTATION_AVAILABLE


class AdaptationEngineBridge:
    """
    Bridge to Rust or Python AdaptationEngine.

    Uses Rust implementation when available for ~10x faster weight updates.
    Falls back to pure Python implementation when Rust is not compiled.
    """

    def __init__(
        self,
        learning_rate: Optional[float] = None,
        use_rust: bool = True,
        tenant_id: str = "default",
    ) -> None:
        """Initialize bridge with optional Rust backend."""
        from somabrain.brain_settings.models import BrainSetting

        if learning_rate is None:
            learning_rate = BrainSetting.get("adapt_lr", tenant_id)

        self._use_rust = use_rust and RUST_ADAPTATION_AVAILABLE
        self._tenant_id = tenant_id

        if self._use_rust:
            self._rust_engine = RustAdaptationEngine(learning_rate)
            logger.debug("Using Rust AdaptationEngine")
        else:
            self._rust_engine = None
            # State for Python fallback - NO MAGIC NUMBERS
            self._retrieval = {
                "alpha": BrainSetting.get("retrieval_alpha", tenant_id),
                "beta": BrainSetting.get("retrieval_beta", tenant_id),
                "gamma": BrainSetting.get("retrieval_gamma", tenant_id),
                "tau": BrainSetting.get("retrieval_tau", tenant_id),
            }
            self._utility = {
                "lambda_": BrainSetting.get("utility_lambda", tenant_id),
                "mu": BrainSetting.get("utility_mu", tenant_id),
                "nu": BrainSetting.get("utility_nu", tenant_id),
            }
            self._learning_rate = learning_rate
            self._base_lr = learning_rate
            self._feedback_count = 0
            # Constraints and gains from settings (adapt category)
            self._constraints = {
                "alpha": (BrainSetting.get("adapt_alpha_min", tenant_id),
                          BrainSetting.get("adapt_alpha_max", tenant_id)),
                "gamma": (BrainSetting.get("adapt_gamma_min", tenant_id),
                          BrainSetting.get("adapt_gamma_max", tenant_id)),
                "lambda_": (BrainSetting.get("adapt_lambda_min", tenant_id),
                            BrainSetting.get("adapt_lambda_max", tenant_id)),
                "mu": (BrainSetting.get("adapt_mu_min", tenant_id),
                       BrainSetting.get("adapt_mu_max", tenant_id)),
                "nu": (BrainSetting.get("adapt_nu_min", tenant_id),
                       BrainSetting.get("adapt_nu_max", tenant_id)),
            }
            self._gains = {
                "alpha": BrainSetting.get("adapt_gain_alpha", tenant_id),
                "gamma": BrainSetting.get("adapt_gain_gamma", tenant_id),
                "lambda_": BrainSetting.get("adapt_gain_lambda", tenant_id),
                "mu": BrainSetting.get("adapt_gain_mu", tenant_id),
                "nu": BrainSetting.get("adapt_gain_nu", tenant_id),
            }

    @property
    def using_rust(self) -> bool:
        """Check if using Rust backend."""
        return self._use_rust

    def set_retrieval(
        self, alpha: float, beta: float, gamma: float, tau: float
    ) -> None:
        """Set retrieval weights."""
        if self._use_rust:
            self._rust_engine.set_retrieval(alpha, beta, gamma, tau)
        else:
            self._retrieval = {"alpha": alpha, "beta": beta, "gamma": gamma, "tau": tau}

    def get_retrieval(self) -> Tuple[float, float, float, float]:
        """Get retrieval weights."""
        if self._use_rust:
            return self._rust_engine.get_retrieval()
        return (
            self._retrieval["alpha"],
            self._retrieval["beta"],
            self._retrieval["gamma"],
            self._retrieval["tau"],
        )

    def set_utility(self, lambda_: float, mu: float, nu: float) -> None:
        """Set utility weights."""
        if self._use_rust:
            self._rust_engine.set_utility(lambda_, mu, nu)
        else:
            self._utility = {"lambda_": lambda_, "mu": mu, "nu": nu}

    def get_utility(self) -> Tuple[float, float, float]:
        """Get utility weights."""
        if self._use_rust:
            return self._rust_engine.get_utility()
        return (self._utility["lambda_"], self._utility["mu"], self._utility["nu"])

    def apply_feedback(self, utility_signal: float, reward: float) -> bool:
        """Apply feedback and update weights - CPU-bound hot path."""
        if self._use_rust:
            return self._rust_engine.apply_feedback(utility_signal, reward)

        # Python fallback
        semantic_signal = reward
        utility_val = utility_signal

        # Update retrieval weights
        self._retrieval["alpha"] = self._clamp(
            self._retrieval["alpha"]
            + self._learning_rate * self._gains["alpha"] * semantic_signal,
            *self._constraints["alpha"],
        )
        self._retrieval["gamma"] = self._clamp(
            self._retrieval["gamma"]
            + self._learning_rate * self._gains["gamma"] * semantic_signal,
            *self._constraints["gamma"],
        )

        # Update utility weights
        self._utility["lambda_"] = self._clamp(
            self._utility["lambda_"]
            + self._learning_rate * self._gains["lambda_"] * utility_val,
            *self._constraints["lambda_"],
        )
        self._utility["mu"] = self._clamp(
            self._utility["mu"] + self._learning_rate * self._gains["mu"] * utility_val,
            *self._constraints["mu"],
        )
        self._utility["nu"] = self._clamp(
            self._utility["nu"] + self._learning_rate * self._gains["nu"] * utility_val,
            *self._constraints["nu"],
        )

        self._feedback_count += 1
        return True

    def _clamp(self, value: float, lower: float, upper: float) -> float:
        """Clamp value to bounds."""
        return min(max(value, lower), upper)

    def get_tau(self) -> float:
        """Get current tau value."""
        if self._use_rust:
            return self._rust_engine.get_tau()
        return self._retrieval["tau"]

    def set_tau(self, tau: float) -> None:
        """Set tau value."""
        if self._use_rust:
            self._rust_engine.set_tau(tau)
        else:
            self._retrieval["tau"] = max(0.01, min(10.0, tau))

    def apply_tau_decay(self, decay_rate: float, min_tau: float) -> None:
        """Apply tau decay."""
        if self._use_rust:
            self._rust_engine.apply_tau_decay(decay_rate, min_tau)
        else:
            self._retrieval["tau"] = max(
                min_tau, self._retrieval["tau"] * (1.0 - decay_rate)
            )

    @property
    def learning_rate(self) -> float:
        """Get learning rate."""
        if self._use_rust:
            return self._rust_engine.learning_rate
        return self._learning_rate

    def update_learning_rate(self, dopamine: float) -> None:
        """Update learning rate based on dopamine level."""
        if self._use_rust:
            self._rust_engine.update_learning_rate(dopamine)
        else:
            lr_scale = max(0.5, min(1.2, 0.5 + dopamine))
            self._learning_rate = self._base_lr * lr_scale

    def reset(self) -> None:
        """Reset engine to defaults."""
        if self._use_rust:
            self._rust_engine.reset()
        else:
            self._retrieval = {"alpha": 1.0, "beta": 0.2, "gamma": 0.1, "tau": 0.7}
            self._utility = {"lambda_": 1.0, "mu": 0.1, "nu": 0.05}
            self._learning_rate = self._base_lr
            self._feedback_count = 0

    def get_feedback_count(self) -> int:
        """Get feedback count."""
        if self._use_rust:
            return self._rust_engine.get_feedback_count()
        return self._feedback_count


# Convenience function for quick instantiation
def get_adaptation_engine(
    learning_rate: float = 0.05,
    prefer_rust: bool = True,
) -> AdaptationEngineBridge:
    """
    Get an AdaptationEngine instance.

    Uses Rust backend when available for ~10x performance.
    """
    return AdaptationEngineBridge(learning_rate=learning_rate, use_rust=prefer_rust)
