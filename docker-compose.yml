name: somabrain

services:
  somabrain_redis:
    image: redis:7.2-alpine
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 32M
        reservations:
          memory: 16M
    networks:
      - somabrain_net
    ports:
      - "${REDIS_HOST_PORT}:${REDIS_CONTAINER_PORT}"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
    volumes:
      - redis_data:/data
    command: ["sh", "-c", "rm -f /data/dump.rdb && redis-server"]

  somabrain_kafka:
    image: apache/kafka:3.7.0
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    environment:
      KAFKA_CFG_NODE_ID: ${KAFKA_CFG_NODE_ID}
      KAFKA_CFG_PROCESS_ROLES: ${KAFKA_CFG_PROCESS_ROLES}
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CFG_CONTROLLER_QUORUM_VOTERS}
      KAFKA_CFG_LISTENERS: ${KAFKA_CFG_LISTENERS}
      KAFKA_CFG_ADVERTISED_LISTENERS: ${KAFKA_CFG_ADVERTISED_LISTENERS}
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: ${KAFKA_CFG_CONTROLLER_LISTENER_NAMES}
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: ${KAFKA_CFG_INTER_BROKER_LISTENER_NAME}
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP}
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE}
      KAFKA_CFG_NUM_PARTITIONS: ${KAFKA_CFG_NUM_PARTITIONS}
      KAFKA_CFG_DEFAULT_REPLICATION_FACTOR: ${KAFKA_CFG_DEFAULT_REPLICATION_FACTOR}
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR}
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR}
      KAFKA_CFG_LOG_DIRS: ${KAFKA_CFG_LOG_DIRS}
      KAFKA_CFG_LOG_RETENTION_MS: ${KAFKA_CFG_LOG_RETENTION_MS}
      KAFKA_CFG_LOG_SEGMENT_BYTES: ${KAFKA_CFG_LOG_SEGMENT_BYTES}
      KAFKA_CFG_LOG_RETENTION_BYTES: ${KAFKA_CFG_LOG_RETENTION_BYTES}
      KAFKA_CFG_COMPRESSION_TYPE: ${KAFKA_CFG_COMPRESSION_TYPE}
      KAFKA_HEAP_OPTS: ${KAFKA_HEAP_OPTS}
      KAFKA_CLUSTER_ID: ${KAFKA_CLUSTER_ID}
    volumes:
      - kafka_data:/var/lib/kafka
    command:
      - bash
      - -c
      - |
          set -e
          mkdir -p /var/lib/kafka/data
          CONFIG_PATH=/tmp/kafka-server.properties
          cp /opt/kafka/config/kraft/server.properties "$${CONFIG_PATH}"
          {
            echo "process.roles=$${KAFKA_CFG_PROCESS_ROLES}"
            echo "node.id=$${KAFKA_CFG_NODE_ID}"
            # Some base configs may still read broker.id; set it explicitly for safety
            echo "broker.id=$${KAFKA_CFG_NODE_ID}"
            echo "controller.listener.names=$${KAFKA_CFG_CONTROLLER_LISTENER_NAMES}"
            echo "controller.quorum.voters=$${KAFKA_CFG_CONTROLLER_QUORUM_VOTERS}"
            echo "listeners=$${KAFKA_CFG_LISTENERS}"
            echo "advertised.listeners=$${KAFKA_CFG_ADVERTISED_LISTENERS}"
            echo "listener.security.protocol.map=$${KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP}"
            echo "inter.broker.listener.name=$${KAFKA_CFG_INTER_BROKER_LISTENER_NAME}"
            echo "log.dirs=$${KAFKA_CFG_LOG_DIRS}"
            echo "auto.create.topics.enable=$${KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE}"
            echo "num.partitions=$${KAFKA_CFG_NUM_PARTITIONS}"
            echo "default.replication.factor=$${KAFKA_CFG_DEFAULT_REPLICATION_FACTOR}"
            echo "offsets.topic.replication.factor=$${KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR}"
            echo "transaction.state.log.replication.factor=$${KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}"
            echo "transaction.state.log.min.isr=$${KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR}"
            echo "compression.type=$${KAFKA_CFG_COMPRESSION_TYPE}"
            echo "log.retention.ms=$${KAFKA_CFG_LOG_RETENTION_MS}"
            echo "log.segment.bytes=$${KAFKA_CFG_LOG_SEGMENT_BYTES}"
            echo "log.retention.bytes=$${KAFKA_CFG_LOG_RETENTION_BYTES}"
          } >> "$${CONFIG_PATH}"
          if [ ! -f /var/lib/kafka/data/meta.properties ]; then
            /opt/kafka/bin/kafka-storage.sh format --ignore-formatted --cluster-id ${KAFKA_CLUSTER_ID:-79LccNO-Qe6G6YgqP1Zrew} --config "$${CONFIG_PATH}"
          fi
          exec /opt/kafka/bin/kafka-server-start.sh "$${CONFIG_PATH}"
    ports:
      # Expose only the EXTERNAL listener container port to the host
      - "${KAFKA_BROKER_HOST_PORT}:${KAFKA_BROKER_EXTERNAL_CONTAINER_PORT}"
    healthcheck:
      test: ["CMD", "bash", "-c", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:${KAFKA_BROKER_CONTAINER_PORT} >/dev/null 2>&1"]
      interval: 15s
      timeout: 10s
      retries: 6
    networks:
      - somabrain_net

  somabrain_kafka_exporter:
    image: danielqsj/kafka-exporter:v1.7.0
    restart: unless-stopped
    command:
      - --kafka.server=somabrain_kafka:${KAFKA_BROKER_CONTAINER_PORT}
    deploy:
      resources:
        limits:
          memory: 64M
        reservations:
          memory: 32M
    depends_on:
      somabrain_kafka:
        condition: service_healthy
    ports:
      - "${KAFKA_EXPORTER_HOST_PORT}:${KAFKA_EXPORTER_CONTAINER_PORT}"
    networks:
      - somabrain_net
    healthcheck:
      test: ["CMD", "wget", "-qO", "/dev/null", "http://localhost:${KAFKA_EXPORTER_CONTAINER_PORT}/"]
      interval: 30s
      timeout: 5s
      retries: 3

  somabrain_kafka_init:
    image: apache/kafka:3.7.0
    restart: "no"
    depends_on:
      somabrain_kafka:
        condition: service_healthy
    networks:
      - somabrain_net
    entrypoint: ["/opt/kafka/bin/kafka-topics.sh"]
    command:
      [
        "--create",
        "--if-not-exists",
        "--topic",
        "soma.audit",
        "--bootstrap-server",
        "somabrain_kafka:${KAFKA_BROKER_CONTAINER_PORT}",
        "--partitions",
        "2",
        "--replication-factor",
        "1",
      ]

  somabrain_schema_registry:
    image: confluentinc/cp-schema-registry:7.6.0
    restart: unless-stopped
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://somabrain_kafka:${KAFKA_BROKER_CONTAINER_PORT}"
    depends_on:
      somabrain_kafka:
        condition: service_healthy
    networks:
      - somabrain_net
    ports:
      - "${SCHEMA_REGISTRY_HOST_PORT:-30008}:8081"
    healthcheck:
      test: ["CMD", "wget", "-qO", "/dev/null", "http://localhost:8081/subjects"]
      interval: 30s
      timeout: 5s
      retries: 3

  somabrain_opa:
    image: openpolicyagent/opa:0.54.0
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 64M
        reservations:
          memory: 32M
    command: ["run", "--server", "--addr=0.0.0.0:${OPA_CONTAINER_PORT}", "--diagnostic-addr=0.0.0.0:8282", "/policies"]
    networks:
      - somabrain_net
    ports:
      - "${OPA_HOST_PORT}:${OPA_CONTAINER_PORT}"
    volumes:
      - ./ops/opa/policies:/policies:ro
      - opa_data:/var/lib/opa
    healthcheck:
      test: ["CMD", "opa", "eval", "--format=raw", "http.send({\"method\": \"GET\", \"url\": \"http://127.0.0.1:${OPA_CONTAINER_PORT}/health?plugins\"}).status == \"200 OK\""]
      interval: 30s
      timeout: 5s
      retries: 3

  somabrain_prometheus:
    image: prom/prometheus:v2.49.0
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    networks:
      - somabrain_net
    ports:
      - "${PROMETHEUS_HOST_PORT}:${PROMETHEUS_CONTAINER_PORT}"
    volumes:
      - ./ops/prometheus/etc/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus

  somabrain_postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    ports:
      - "${POSTGRES_HOST_PORT}:${POSTGRES_CONTAINER_PORT}"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - somabrain_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 5s
      retries: 3

  somabrain_db_migrate:
    image: somabrain:latest
    depends_on:
      somabrain_postgres:
        condition: service_healthy
    networks:
      - somabrain_net
    environment:
      # Use the internal service hostname to reach Postgres from within the network
      # Compose will substitute these from your .env
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      POSTGRES_DB: "${POSTGRES_DB}"
      SOMABRAIN_POSTGRES_DSN: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@somabrain_postgres:5432/${POSTGRES_DB}"
    # Dev convenience: try to upgrade; if the schema already exists without Alembic history,
    # stamp to heads to align the version table. Safe for local dev; don't use this in prod.
    command: ["sh", "-lc", "cd /app && alembic -c /app/alembic.ini upgrade heads || alembic -c /app/alembic.ini stamp heads"]
    restart: "no"
    profiles: ["dev"]

  somabrain_postgres_exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 64M
        reservations:
          memory: 32M
    environment:
      - DATA_SOURCE_NAME=${SOMABRAIN_POSTGRES_DSN}?sslmode=disable
    depends_on:
      somabrain_postgres:
        condition: service_healthy
    ports:
      - "${POSTGRES_EXPORTER_HOST_PORT}:${POSTGRES_EXPORTER_CONTAINER_PORT}"
    networks:
      - somabrain_net
    healthcheck:
      test: ["CMD", "wget", "-qO", "/dev/null", "http://localhost:${POSTGRES_EXPORTER_CONTAINER_PORT}/"]
      interval: 30s
      timeout: 5s
      retries: 3

  somabrain_app:
    build:
      context: .
      dockerfile: Dockerfile
    image: somabrain:latest
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 96M
    depends_on:
      somabrain_redis:
        condition: service_healthy
      somabrain_kafka:
        condition: service_healthy
      somabrain_opa:
        condition: service_healthy
      somabrain_postgres:
        condition: service_healthy
    networks:
      - somabrain_net
    environment:
      # Explicitly require a real external memory service; no dev fallback
      SOMABRAIN_MEMORY_HTTP_ENDPOINT: "${SOMABRAIN_MEMORY_HTTP_ENDPOINT}"
      SOMABRAIN_MEMORY_HTTP_TOKEN: "${SOMABRAIN_MEMORY_HTTP_TOKEN}"
      SOMABRAIN_HOST: "${SOMABRAIN_HOST:-0.0.0.0}"
      SOMABRAIN_PORT: "${SOMABRAIN_PORT:-9696}"
      SOMABRAIN_WORKERS: "${SOMABRAIN_WORKERS:-1}"
      SOMABRAIN_REDIS_URL: "${SOMABRAIN_REDIS_URL}"
      SOMABRAIN_KAFKA_URL: "${SOMABRAIN_KAFKA_URL}"
      SOMA_KAFKA_BOOTSTRAP: "somabrain_kafka:${KAFKA_BROKER_CONTAINER_PORT}"
      SOMABRAIN_OPA_URL: "${SOMABRAIN_OPA_URL}"
      SOMABRAIN_POSTGRES_DSN: "${SOMABRAIN_POSTGRES_DSN}"
      SOMABRAIN_REQUIRE_EXTERNAL_BACKENDS: "${SOMABRAIN_REQUIRE_EXTERNAL_BACKENDS:-1}"
      SOMABRAIN_FORCE_FULL_STACK: "${SOMABRAIN_FORCE_FULL_STACK:-1}"
      SOMABRAIN_REQUIRE_MEMORY: "${SOMABRAIN_REQUIRE_MEMORY:-1}"
      SOMABRAIN_PREDICTOR_PROVIDER: "${SOMABRAIN_PREDICTOR_PROVIDER:-mahal}"
      SOMABRAIN_MEMORY_ENABLE_WEIGHTING: "${SOMABRAIN_MEMORY_ENABLE_WEIGHTING:-0}"
      SOMABRAIN_MEMORY_PHASE_PRIORS: "${SOMABRAIN_MEMORY_PHASE_PRIORS:-}"
      SOMABRAIN_MEMORY_QUALITY_EXP: "${SOMABRAIN_MEMORY_QUALITY_EXP:-1.0}"
      SOMABRAIN_DEFAULT_TENANT: "${SOMABRAIN_DEFAULT_TENANT:-sandbox}"
      SOMABRAIN_MODE: "${SOMABRAIN_MODE:-enterprise}"
      SUPERVISOR_HTTP_USER: "${SUPERVISOR_HTTP_USER:-admin}"
      SUPERVISOR_HTTP_PASS: "${SUPERVISOR_HTTP_PASS:-soma}"
    ports:
      - "${SOMABRAIN_HOST_PORT}:${SOMABRAIN_PORT}"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:${SOMABRAIN_PORT}/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
    # No local journal volume; fail-fast only
    # Security hardening: drop all capabilities, run with read-only rootfs, and disallow privilege escalation.
    # Note: we mount a tmpfs for /app/logs to keep runtime logs writable.
    cap_drop: ["ALL"]
    read_only: true
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /app/logs

  somabrain_cog:
    build:
      context: .
      dockerfile: Dockerfile
    image: somabrain:latest
    restart: unless-stopped
    depends_on:
      somabrain_kafka:
        condition: service_healthy
      somabrain_postgres:
        condition: service_healthy
      somabrain_redis:
        condition: service_healthy
      somabrain_opa:
        condition: service_healthy
    networks:
      - somabrain_net
    environment:
      # Explicitly require a real external memory service; no dev fallback
      SOMABRAIN_MEMORY_HTTP_ENDPOINT: "${SOMABRAIN_MEMORY_HTTP_ENDPOINT}"
      SOMABRAIN_STRICT_REAL: "1"
      SOMA_HEAT_METHOD: "lanczos"
      SOMABRAIN_ENABLE_TEACH_FEEDBACK: "1"
      ENABLE_COG_THREADS: "${ENABLE_COG_THREADS:-1}"
      SOMABRAIN_REDIS_URL: "${SOMABRAIN_REDIS_URL}"
      SOMABRAIN_KAFKA_URL: "${SOMABRAIN_KAFKA_URL}"
      SOMA_KAFKA_BOOTSTRAP: "somabrain_kafka:${KAFKA_BROKER_CONTAINER_PORT}"
      SOMABRAIN_OPA_URL: "${SOMABRAIN_OPA_URL}"
      SOMABRAIN_POSTGRES_DSN: "${SOMABRAIN_POSTGRES_DSN}"
      SOMABRAIN_DEFAULT_TENANT: "${SOMABRAIN_DEFAULT_TENANT}"
      # Supervisor HTTP auth used by API for control; only on internal network
      SUPERVISOR_HTTP_USER: "${SUPERVISOR_HTTP_USER:-admin}"
      SUPERVISOR_HTTP_PASS: "${SUPERVISOR_HTTP_PASS:-soma}"
    command: ["/usr/bin/supervisord", "-c", "/app/ops/supervisor/supervisord.conf"]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://admin:soma@localhost:9001"]
      interval: 30s
      timeout: 5s
      retries: 5
    cap_drop: ["ALL"]
    read_only: true
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /app/logs
      - /tmp

  somabrain_outbox_publisher:
    build:
      context: .
      dockerfile: Dockerfile
    image: somabrain:latest
    restart: unless-stopped
    depends_on:
      somabrain_kafka:
        condition: service_healthy
      somabrain_postgres:
        condition: service_healthy
    networks:
      - somabrain_net
    command: ["python", "-m", "somabrain.workers.outbox_publisher"]
    environment:
      SOMABRAIN_PREDICTOR_PROVIDER: "${SOMABRAIN_PREDICTOR_PROVIDER:-mahal}"
      SOMABRAIN_REQUIRE_EXTERNAL_BACKENDS: "${SOMABRAIN_REQUIRE_EXTERNAL_BACKENDS:-1}"
      SOMABRAIN_FORCE_FULL_STACK: "${SOMABRAIN_FORCE_FULL_STACK:-1}"
      SOMABRAIN_REDIS_URL: "${SOMABRAIN_REDIS_URL}"
      SOMABRAIN_KAFKA_URL: "${SOMABRAIN_KAFKA_URL}"
      SOMA_KAFKA_BOOTSTRAP: "somabrain_kafka:${KAFKA_BROKER_CONTAINER_PORT}"
      SOMABRAIN_OPA_URL: "${SOMABRAIN_OPA_URL}"
      SOMABRAIN_POSTGRES_DSN: "${SOMABRAIN_POSTGRES_DSN}"
      SOMABRAIN_OUTBOX_BATCH_SIZE: ${SOMABRAIN_OUTBOX_BATCH_SIZE:-100}
      SOMABRAIN_OUTBOX_MAX_DELAY: ${SOMABRAIN_OUTBOX_MAX_DELAY:-5.0}
    # No journal mount required
    cap_drop: ["ALL"]
    read_only: true
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /app/logs
      - /tmp
    healthcheck:
      test: ["CMD", "true"]
      interval: 30s
      timeout: 5s
      retries: 1

  


  # --- Cognitive Thread: Predictors ----------------------------------------

  # --- Cognitive Thread: Integrator + Segmentation + Orchestrator ----------

volumes:
  kafka_data:
    driver: local
  postgres_data:
    driver: local
  redis_data:
    driver: local
  opa_data:
    driver: local
  prometheus_data:
    driver: local
  

networks:
  somabrain_net:
    driver: bridge
