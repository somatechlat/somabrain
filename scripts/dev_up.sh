#!/usr/bin/env bash
set -euo pipefail
# dev_up.sh - single canonical helper to start the dev stack
# Behavior:
# - Detect free host ports for key services (if default port in use, pick next free)
# - Write .env with chosen host port mappings
# - Start docker compose with docker-compose.yml using .env
# - Wait for somabrain health endpoint and write ports.json for testers

ROOT=$(cd "$(dirname "$0")/.." && pwd)
cd "$ROOT"

ENVFILE=.env
echo "# Generated by scripts/dev_up.sh" > $ENVFILE
echo "COMPOSE_PROJECT_NAME=somabrain" >> $ENVFILE

# Sanitize environment so host-level overrides don't leak into compose
unset SOMABRAIN_KAFKA_URL || true
unset SOMABRAIN_POSTGRES_DSN || true
unset SOMABRAIN_REDIS_URL || true
unset POSTGRES_USER || true
unset POSTGRES_PASSWORD || true
unset POSTGRES_DB || true
unset KAFKA_CFG_NODE_ID || true
unset KAFKA_CFG_PROCESS_ROLES || true
unset KAFKA_CFG_CONTROLLER_QUORUM_VOTERS || true
unset KAFKA_CFG_LISTENERS || true
unset KAFKA_CFG_ADVERTISED_LISTENERS || true
unset KAFKA_CFG_CONTROLLER_LISTENER_NAMES || true
unset KAFKA_CFG_INTER_BROKER_LISTENER_NAME || true
unset KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP || true
unset KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE || true
unset KAFKA_CFG_NUM_PARTITIONS || true
unset KAFKA_CFG_DEFAULT_REPLICATION_FACTOR || true
unset KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR || true
unset KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR || true
unset KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR || true
unset KAFKA_CFG_LOG_DIRS || true
unset KAFKA_CFG_LOG_RETENTION_MS || true
unset KAFKA_CFG_LOG_SEGMENT_BYTES || true
unset KAFKA_CFG_LOG_RETENTION_BYTES || true
unset KAFKA_CFG_COMPRESSION_TYPE || true
unset KAFKA_HEAP_OPTS || true
unset KAFKA_CLUSTER_ID || true

# Function to find next available port starting from a given port
find_free_port() {
    local start_port=$1
    local port=$start_port
    while lsof -i :$port >/dev/null 2>&1; do
        ((port++))
        if [ $port -gt 65535 ]; then
            echo "ERROR: No available ports found starting from $start_port" >&2
            return 1
        fi
    done
    echo $port
}

# Fixed container ports, host ports allocated from 30000+ range
REDIS_PORT=$(find_free_port 30000)
# Host port for EXTERNAL Kafka listener; choose a free one in 301xx range
KAFKA_BROKER_PORT=$(find_free_port 30102)
KAFKA_EXPORTER_PORT=$(find_free_port 30003)
OPA_PORT=$(find_free_port 30004)
PROMETHEUS_PORT=$(find_free_port 30005)
POSTGRES_PORT=$(find_free_port 30006)
POSTGRES_EXPORTER_PORT=$(find_free_port 30007)
API_HOST_PORT=9696

echo "Port allocation (host ports):"
echo "  Redis: $REDIS_PORT"
echo "  Kafka Broker: $KAFKA_BROKER_PORT"
echo "  Kafka Exporter: $KAFKA_EXPORTER_PORT"
echo "  OPA: $OPA_PORT"
echo "  Prometheus: $PROMETHEUS_PORT"
echo "  Postgres: $POSTGRES_PORT"
echo "  Postgres Exporter: $POSTGRES_EXPORTER_PORT"
echo "  SomaBrain API: $API_HOST_PORT (fixed)"

# Write detected ports
cat <<PORTS >> $ENVFILE
# Container port constants (avoid relying on base .env)
REDIS_CONTAINER_PORT=6379
KAFKA_BROKER_CONTAINER_PORT=9092
KAFKA_BROKER_EXTERNAL_CONTAINER_PORT=9094
KAFKA_EXPORTER_CONTAINER_PORT=9308
OPA_CONTAINER_PORT=8181
PROMETHEUS_CONTAINER_PORT=9090
POSTGRES_CONTAINER_PORT=5432
POSTGRES_EXPORTER_CONTAINER_PORT=9187
SOMABRAIN_PORT=9696

REDIS_HOST_PORT=$REDIS_PORT
KAFKA_BROKER_HOST_PORT=$KAFKA_BROKER_PORT
KAFKA_EXPORTER_HOST_PORT=$KAFKA_EXPORTER_PORT
OPA_HOST_PORT=$OPA_PORT
PROMETHEUS_HOST_PORT=$PROMETHEUS_PORT
POSTGRES_HOST_PORT=$POSTGRES_PORT
POSTGRES_EXPORTER_HOST_PORT=$POSTGRES_EXPORTER_PORT
SOMABRAIN_HOST_PORT=$API_HOST_PORT
PORTS

# Require an external memory service reachable from containers (default host gateway on macOS)
# Resolve defaults at script time so containers see concrete values
SOMABRAIN_MEMORY_HTTP_ENDPOINT=${SOMABRAIN_MEMORY_HTTP_ENDPOINT:-http://host.docker.internal:9595}
SOMABRAIN_MEMORY_HTTP_TOKEN=${SOMABRAIN_MEMORY_HTTP_TOKEN:-dev-token-allow}
echo "SOMABRAIN_MEMORY_HTTP_ENDPOINT=${SOMABRAIN_MEMORY_HTTP_ENDPOINT}" >> $ENVFILE
echo "SOMABRAIN_MEMORY_HTTP_TOKEN=${SOMABRAIN_MEMORY_HTTP_TOKEN}" >> $ENVFILE
echo "SOMABRAIN_DOCKER_MEMORY_FALLBACK=http://host.docker.internal:9595" >> $ENVFILE

# Production-like defaults for development: backend enforcement and full stack
cat <<'FLAGS' >> $ENVFILE
SOMABRAIN_FORCE_FULL_STACK=1
SOMABRAIN_REQUIRE_EXTERNAL_BACKENDS=1
SOMABRAIN_REQUIRE_MEMORY=1
SOMABRAIN_MODE=enterprise
SOMABRAIN_PREDICTOR_PROVIDER=mahal
FLAGS

# App-level sane defaults to avoid compose warnings
cat <<'APPVARS' >> $ENVFILE
SOMABRAIN_HOST=0.0.0.0
SOMABRAIN_WORKERS=1
SOMABRAIN_DEFAULT_TENANT=sandbox
SOMABRAIN_MEMORY_ENABLE_WEIGHTING=0
SOMABRAIN_MEMORY_PHASE_PRIORS=
SOMABRAIN_MEMORY_QUALITY_EXP=1.0
APPVARS

# In-cluster service URLs for containers
cat <<'INCLUSTER' >> $ENVFILE
SOMABRAIN_REDIS_URL=redis://somabrain_redis:6379/0
SOMABRAIN_KAFKA_URL=kafka://somabrain_kafka:9092
SOMABRAIN_OPA_URL=http://somabrain_opa:8181
POSTGRES_USER=soma
POSTGRES_PASSWORD=soma_pass
POSTGRES_DB=somabrain
SOMABRAIN_POSTGRES_DSN=postgresql://soma:soma_pass@somabrain_postgres:5432/somabrain
INCLUSTER

# Kafka KRaft single-node defaults
cat <<KRAFT >> $ENVFILE
KAFKA_CFG_NODE_ID=1
KAFKA_CFG_PROCESS_ROLES=broker,controller
KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@somabrain_kafka:9093
KAFKA_CFG_LISTENERS=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093
## For remote clients (or WSL2), set KAFKA_EXTERNAL_HOST to your host IP/DNS before running this script.
## Example: KAFKA_EXTERNAL_HOST=192.168.1.10 ./scripts/dev_up.sh
KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://somabrain_kafka:9092,EXTERNAL://__EXT_HOST__
KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
KAFKA_CFG_NUM_PARTITIONS=2
KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=1
KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
KAFKA_CFG_LOG_DIRS=/var/lib/kafka/data
KAFKA_CFG_LOG_RETENTION_MS=604800000
KAFKA_CFG_LOG_SEGMENT_BYTES=52428800
KAFKA_CFG_LOG_RETENTION_BYTES=536870912
KAFKA_CFG_COMPRESSION_TYPE=snappy
KAFKA_HEAP_OPTS=-Xmx384m -Xms256m
KAFKA_CLUSTER_ID=79LccNO-Qe6G6YgqP1Zrew
KRAFT

# Resolve advertised external listener host (default localhost unless KAFKA_EXTERNAL_HOST is set)
EXT_HOST=${KAFKA_EXTERNAL_HOST:-localhost}
sed -i '' -e "s#__EXT_HOST__#${EXT_HOST}:${KAFKA_BROKER_PORT}#g" "$ENVFILE" 2>/dev/null || \
    sed -i -e "s#__EXT_HOST__#${EXT_HOST}:${KAFKA_BROKER_PORT}#g" "$ENVFILE"

echo "Wrote $ENVFILE:" && sed -n '1,200p' $ENVFILE

echo "Cleaning any previous compose state (down --remove-orphans)"
docker compose --env-file "$ENVFILE" -f docker-compose.yml down --remove-orphans || true
echo "Bringing up docker compose (this will build the somabrain image)..."
docker compose --env-file "$ENVFILE" -f docker-compose.yml up -d --build somabrain_app somabrain_outbox_publisher

# Wait for somabrain health
API_HOST_PORT_LOCAL=$(grep '^SOMABRAIN_HOST_PORT=' $ENVFILE | cut -d= -f2)
echo "Waiting for somabrain on http://localhost:${API_HOST_PORT_LOCAL}/health"
for i in $(seq 1 60); do
    if curl -fsS "http://localhost:${API_HOST_PORT_LOCAL}/health" >/dev/null 2>&1; then
    echo "somabrain healthy"
    break
  fi
  sleep 2
done

echo "Writing ports.json"
python3 - <<PY
import json,subprocess
env={}
with open('.env') as f:
    for l in f:
        if '=' in l:
            k,v=l.strip().split('=',1)
            env[k]=v
ports={}
ports.update(env)
services=['somabrain_app','somabrain_redis','somabrain_kafka','somabrain_prometheus','somabrain_postgres','somabrain_kafka_exporter','somabrain_postgres_exporter','somabrain_opa']
port_map={'somabrain_app':'9696','somabrain_redis':'6379','somabrain_kafka':'9094','somabrain_prometheus':'9090','somabrain_postgres':'5432','somabrain_kafka_exporter':'9308','somabrain_postgres_exporter':'9187','somabrain_opa':'8181'}
for s in services:
    try:
        # Map each service to its container port for port lookup
        container_port = port_map[s]
        out=subprocess.check_output(['docker','compose','-f','docker-compose.yml','port',s,container_port], text=True).strip()
        ports[s+'_host_mapping']=out
    except Exception:
        ports[s+'_host_mapping']=''
open('ports.json','w').write(json.dumps(ports,indent=2))
print('wrote ports.json')
PY

echo "Done. Use ports.json for test harness or inspect with 'cat ports.json'"
