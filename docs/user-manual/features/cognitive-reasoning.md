# Cognitive Reasoning

**Purpose** Explain how SomaBrain builds contextual prompts, applies feedback, and updates its learning state.

**Audience** Users who need more than simple recall and want to use `/context/evaluate`, `/context/feedback`, sleep consolidation, and neuromodulation endpoints.

**Prerequisites** Completed the [Quick Start Tutorial](../quick-start-tutorial.md) and understand [Memory Operations](memory-operations.md).

---

## 1. Context Evaluation (`/context/evaluate`)

The evaluate endpoint orchestrates the `ContextBuilder`, `ContextPlanner`, and associated scoring logic. It returns a structured response defined in `somabrain/api/schemas/context.py::EvaluateResponse`.

### Request

```bash
curl -sS http://localhost:9696/context/evaluate \
  -H "Content-Type: application/json" \
  -H "$AUTH" -H "$TENANT" \
  -d '{
        "query": "Summarise our capital city policy",
        "top_k": 5,
        "session_id": "demo-session"
      }' | jq
```

### Response Fields

| Field | Description |
|-------|-------------|
| `prompt` | Generated prompt assembled by `ContextPlanner`, incorporating highlights when useful. |
| `memories` | Array of `MemoryItem` objects (id, score, metadata, optional embedding). |
| `weights` | Per-memory weights computed by `ContextBuilder` using the current retrieval parameters (α, β, γ, τ). |
| `residual_vector` | Residual HRR vector used for downstream models. |
| `working_memory` | Snapshot of the session’s working memory buffer. |
| `constitution_checksum` | Hash of the active constitution document (if configured). |

Evaluation emits metrics (`somabrain.metrics`) and updates the per-tenant tau gauge when duplicate ratios exceed thresholds.

---

## 2. Submitting Feedback (`/context/feedback`)

Feedback nudges the `AdaptationEngine` for a tenant. The update scales are configurable through the environment and shared settings (see `AdaptationGains` and `AdaptationConstraints`).

```bash
curl -sS http://localhost:9696/context/feedback \
  -H "Content-Type: application/json" \
  -H "$AUTH" -H "$TENANT" \
  -d '{
        "session_id": "demo-session",
        "query": "Summarise our capital city policy",
        "prompt": "Summarise the capital city policy succinctly.",
        "response_text": "Paris is recorded as the capital city.",
        "utility": 0.9,
        "reward": 0.9
      }' | jq
```

**Success response**

```json
{
  "accepted": true,
  "adaptation_applied": true
}
```

The engine records a history entry, persists the state to Redis (`adaptation:state:{tenant}`), and emits metrics capturing the new α/β/γ/τ and λ/μ/ν values.

Inspect the current state:

```bash
curl -sS http://localhost:9696/context/adaptation/state \
  -H "$AUTH" -H "$TENANT" | jq
```

Response (`AdaptationStateResponse`) includes retrieval weights, utility weights, effective learning rate, the configured gains, and the active parameter bounds so you can confirm overrides at runtime.

---

## 3. Neuromodulators (`/neuromodulators`)

`somabrain.neuromodulators.PerTenantNeuromodulators` stores dopamine, serotonin, noradrenaline, and acetylcholine levels that influence dynamic learning rates.

```bash
# fetch current state
curl -sS http://localhost:9696/neuromodulators \
  -H "$AUTH" -H "$TENANT" | jq

# update dopamine level
curl -sS http://localhost:9696/neuromodulators \
  -H "Content-Type: application/json" \
  -H "$AUTH" -H "$TENANT" \
  -d '{"dopamine": 0.35}' | jq
```

When `enable_dynamic_lr` is set (via config or `SOMABRAIN_LEARNING_RATE_DYNAMIC=1`), the AdaptationEngine scales the base learning rate by `0.5 + dopamine` (bounded `[0.5, 1.2]`).

---

## 4. Sleep & Consolidation (`/sleep/run`)

Trigger NREM/REM consolidation cycles to summarise working memory content or recombine long-term memories.

```bash
curl -sS http://localhost:9696/sleep/run \
  -H "Content-Type: application/json" \
  -H "$AUTH" -H "$TENANT" \
  -d '{"nrem": true, "rem": true}' | jq
```

The response (`SleepRunResponse`) reports the mode executed, timestamps, and per-phase results (NREM condensation summaries, REM recombination outputs). Internally this drives `somabrain.consolidation` against `MultiTenantWM` and the long-term memory client.

---

## 5. Planner Actions (`/plan/suggest`, `/act`)

- `/plan/suggest` calls `somabrain.planner.plan_from_graph` to propose actions or task decomposition. Provide a `task` string plus optional `top_k`, `tenant`, or history prompts.
- `/act` executes actions generated by the planner or external agents. Payloads follow `somabrain/schemas.py::ActRequest`.

These endpoints are guarded by the same auth and tenant rules as memory operations. Use them in conjunction with the evaluate/feedback loop to maintain consistency between context building and executed plans.

---

## 6. Observability Checklist

| Signal | Source | How to access |
|--------|--------|---------------|
| Adaptation weights | Redis (`adaptation:state:{tenant}`) or `/context/adaptation/state` | `curl` + `jq` |
| Tau adjustments | Prometheus gauge `somabrain_tau_gauge` | `curl http://localhost:9696/metrics` |
| Feedback throughput | Counter `somabrain_feedback_total` | Prometheus |
| Planner latency | Histogram `somabrain_plan_latency_seconds` | Prometheus |
| Working memory size | Gauge `somabrain_wm_utilization` | Prometheus |

Monitor these metrics to ensure reasoning workflows adapt as expected over time.

---

## 7. Teach feedback via Kafka (advanced)

When you need auditable human ratings to influence exploration and policy selection, SomaBrain supports a Kafka-native teach feedback loop.

- Produce TeachFeedback to `cog.teach.feedback` with fields:
  - `feedback_id`, `capsule_id`, `frame_id`, `ts`, `rating` (1–5), `comment`
- The `teach_feedback_processor` consumes `cog.teach.feedback` and emits a `RewardEvent` to `cog.reward.events`, mapping `rating` to `r_user`:
  - 1→-1.0, 2→-0.5, 3→0.0, 4→0.5, 5→1.0; `total=r_user`
- The `learner_online` service reads `cog.reward.events` and updates exploration temperature (`tau`) via `cog.config.updates`.

Quick validation (requires local Kafka):

```bash
# Install preferred Kafka client locally (recommended)
pip install confluent-kafka

# Seed topics (idempotent)
python scripts/seed_topics.py

# Run the smoke test (produces TeachFeedback and waits for a RewardEvent)
python scripts/e2e_teach_feedback_smoke.py
```

Schemas live in `proto/cog/teach_feedback.avsc` and `proto/cog/reward_event.avsc`. See `somabrain/services/teach_feedback_processor.py` for the mapping.

Notes:
- The teach feedback processor publishes rewards using the confluent-kafka client with no compression by default for maximum interoperability.
- The smoke script also prefers confluent-kafka; if unavailable it falls back to kafka-python.
