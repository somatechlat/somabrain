# Visual Guide to SomaBrain Mathematics

**Diagrams, Plots, and Intuitive Explanations**

---

## ğŸ¨ Complete Memory Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SOMABRAIN MEMORY LIFECYCLE                        â”‚
â”‚                                                                      â”‚
â”‚  INPUT â†’ ENCODE â†’ BIND â†’ STORE â†’ DECAY â†’ QUERY â†’ RETRIEVE â†’ OUTPUT â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. INPUT     â”‚  "Paris is the capital of France"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. TOKENIZE  â”‚  ["Paris", "capital", "France"]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. EMBED (2048-D BHDC)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Paris"   â†’ [0.023, -0.041,  0.018, ..., -0.012] (2048) â”‚
â”‚ "capital" â†’ [0.019, -0.011,  0.037, ...,  0.008] (2048) â”‚
â”‚ "France"  â†’ [-0.015, 0.032, -0.028, ...,  0.021] (2048) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. BIND WITH ROLES                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ paris_subject = bind(Paris, role_subject)                â”‚
â”‚ france_object = bind(France, role_object)                â”‚
â”‚ memory = bind(paris_subject, capital) âŠ• france_object    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. STORE IN TRACE (Exponential Decay)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ M_{t+1} = (1-Î·)M_t + Î·Â·memory                           â”‚
â”‚ Î· = 0.08 (decay factor)                                  â”‚
â”‚                                                          â”‚
â”‚ Time 0:  M_0 = memory_0                                  â”‚
â”‚ Time 1:  M_1 = 0.92Â·M_0 + 0.08Â·memory_1                 â”‚
â”‚ Time 2:  M_2 = 0.92Â·M_1 + 0.08Â·memory_2                 â”‚
â”‚          ...                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. QUERY                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User asks: "What is the capital of France?"              â”‚
â”‚ q = embed("capital of France")                           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. UNBIND FROM TRACE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ result = unbind(M_current, q)                            â”‚
â”‚ result â‰ˆ Paris vector (with some noise)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. CLEANUP (Nearest Neighbor)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Anchors:                                                 â”‚
â”‚   "Paris"   â†’ cosine(result, Paris)   = 0.94  â† BEST    â”‚
â”‚   "London"  â†’ cosine(result, London)  = 0.23            â”‚
â”‚   "Berlin"  â†’ cosine(result, Berlin)  = 0.31            â”‚
â”‚   "Rome"    â†’ cosine(result, Rome)    = 0.18            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. OUTPUT    â”‚  "Paris" (confidence: 0.94)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Exponential Decay Visualization

### Memory Contribution Over Time

```
Contribution to Trace (%)
100â”‚ â—                                    Memory inserted at t=0
   â”‚  â•²                                   Î· = 0.08 (decay factor)
 90â”‚   â—
   â”‚    â•²                                 After 8 steps: 50% contribution
 80â”‚     â•²                                After 16 steps: 25% contribution
   â”‚      â—                               After 24 steps: 12.5% contribution
 70â”‚       â•²
   â”‚        â•²
 60â”‚         â—
   â”‚          â•²
 50â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    Half-life â‰ˆ 8.3 steps
   â”‚            â•²
 40â”‚             â•²
   â”‚              â—
 30â”‚               â•²
   â”‚                â•²
 20â”‚                 â—
   â”‚                  â•²
 10â”‚                   â•²â—
   â”‚                     â•²
  0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Time (steps)
    0   5   10  15  20  25  30  35  40

Formula: contribution(t) = (1-Î·)^t = 0.92^t
```

### Multiple Memories in Trace

```
Trace Composition at t=10 (10 memories inserted)

Memory Age    Contribution    Cumulative
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mem_10  (0)   100.0%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
mem_9   (1)    92.0%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   92%
mem_8   (2)    84.6%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     85%
mem_7   (3)    77.9%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      78%
mem_6   (4)    71.6%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       72%
mem_5   (5)    65.9%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        66%
mem_4   (6)    60.6%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         61%
mem_3   (7)    55.8%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          56%
mem_2   (8)    51.3%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           51%
mem_1   (9)    47.2%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            47%
mem_0   (10)   43.4%         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             43%

Total effective memories: ~8.5 (weighted sum)
```

---

## ğŸ¯ BHDC Binding Visualization

### Elementwise Product (Binding)

```
Vector A:  [0.5, -0.3,  0.8, -0.1,  0.6, -0.4]
Vector B:  [0.2,  0.9, -0.4,  0.7, -0.2,  0.5]
           âŠ™â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Product:   [0.1, -0.27, -0.32, -0.07, -0.12, -0.2]
           â”‚
           â”‚ normalize (L2 norm = 1)
           â–¼
Bound:     [0.21, -0.57, -0.67, -0.15, -0.25, -0.42]

Properties:
âœ“ âŸ¨A, BoundâŸ© â‰ˆ 0  (orthogonal to input A)
âœ“ âŸ¨B, BoundâŸ© â‰ˆ 0  (orthogonal to input B)
âœ“ â€–Boundâ€– = 1     (unit norm)
```

### Unbinding (Inverse Operation)

```
Bound:     [0.21, -0.57, -0.67, -0.15, -0.25, -0.42]
Vector B:  [0.2,   0.9,  -0.4,   0.7,  -0.2,   0.5]
           âŠ˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Quotient:  [1.05, -0.63,  1.68, -0.21,  1.25, -0.84]
           â”‚
           â”‚ normalize
           â–¼
Recovered: [0.5,  -0.3,   0.8,  -0.1,   0.6,  -0.4]

âœ“ Recovered = Vector A  (perfect inversion!)
```

---

## ğŸŒ Multi-Signal Scoring

### Unified Scorer Components

```
Query: "capital of France"
Candidate: "Paris" memory

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ COMPONENT 1: COSINE SIMILARITY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cos(query, candidate) = 0.87                            â”‚
â”‚ Weight: w_cosine = 0.6                                  â”‚
â”‚ Contribution: 0.6 Ã— 0.87 = 0.522                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ COMPONENT 2: FD SUBSPACE PROJECTION                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Project to 64-D subspace (captures 90% variance)        â”‚
â”‚ cos(proj_query, proj_candidate) = 0.91                  â”‚
â”‚ Weight: w_fd = 0.3                                      â”‚
â”‚ Contribution: 0.3 Ã— 0.91 = 0.273                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ COMPONENT 3: RECENCY DECAY                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Age: 120 seconds                                        â”‚
â”‚ Decay: exp(-120/60) = exp(-2) = 0.135                  â”‚
â”‚ Weight: w_recency = 0.1                                 â”‚
â”‚ Contribution: 0.1 Ã— 0.135 = 0.014                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FINAL SCORE                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total = 0.522 + 0.273 + 0.014 = 0.809                  â”‚
â”‚ Clamped to [0, 1]: 0.809                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Recency Decay Curve

```
Recency Factor
1.0â”‚â—
   â”‚ â•²
0.9â”‚  â•²
   â”‚   â—
0.8â”‚    â•²
   â”‚     â•²
0.7â”‚      â—
   â”‚       â•²
0.6â”‚        â•²
   â”‚         â—
0.5â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    Half-life = Ï„Â·ln(2) â‰ˆ 42s
   â”‚           â•²
0.4â”‚            â—
   â”‚             â•²
0.3â”‚              â•²
   â”‚               â—
0.2â”‚                â•²
   â”‚                 â•²
0.1â”‚                  â—
   â”‚                   â•²
0.0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â–¶ Age (seconds)
    0   30  60  90  120 150 180

Formula: recency(age) = exp(-age/Ï„)
Ï„ = 60 seconds (configurable)
```

---

## ğŸ§  Adaptive Learning Dynamics

### Weight Evolution Over Time

```
Retrieval Weight Î± (cosine importance)

2.0â”‚                              â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€  Î±_max = 2.0
   â”‚                         â•­â”€â”€â”€â”€â•¯
1.8â”‚                    â•­â”€â”€â”€â”€â•¯
   â”‚               â•­â”€â”€â”€â”€â•¯
1.6â”‚          â•­â”€â”€â”€â”€â•¯
   â”‚     â•­â”€â”€â”€â”€â•¯
1.4â”‚â•­â”€â”€â”€â”€â•¯
   â”‚
1.2â”‚â—                                         Initial: Î± = 1.0
   â”‚                                          Gain: g_Î± = 1.0
1.0â”‚                                          Learning rate: 0.05
   â”‚
0.8â”‚
   â”‚
0.6â”‚
   â”‚
0.4â”‚
   â”‚
0.2â”‚                                          Î±_min = 0.2
0.0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Feedback events
    0   5   10  15  20  25  30  35  40  45

Update rule: Î±_{t+1} = clamp(Î±_t + lrÂ·g_Î±Â·reward, Î±_min, Î±_max)

Positive feedback (reward=1.0):
  Step 0â†’1: Î± = 1.0 + 0.05Ã—1.0Ã—1.0 = 1.05
  Step 1â†’2: Î± = 1.05 + 0.05Ã—1.0Ã—1.0 = 1.10
  ...
  Step 20: Î± â‰ˆ 2.0 (saturated at Î±_max)
```

### Entropy Cap Enforcement

```
Retrieval Parameter Entropy

2.0â”‚
   â”‚  â—  â—  â—                     Before cap: H = 1.95
1.8â”‚   â•²  â”‚  â•±                    (nearly uniform distribution)
   â”‚    â•² â”‚ â•±
1.6â”‚     â•²â”‚â•±
   â”‚      â—
1.4â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    Entropy cap: H_max = 1.4
   â”‚
1.2â”‚
   â”‚         â—                     After cap: H = 1.12
1.0â”‚        â•±â”‚â•²                    (sharpened distribution)
   â”‚       â•± â”‚ â•²
0.8â”‚      â•±  â”‚  â•²
   â”‚     â—   â—   â—
0.6â”‚
   â”‚
0.4â”‚
   â”‚
0.2â”‚
0.0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Feedback events
    0   5   10  15  20  25  30

Entropy formula: H = -Î£ p_iÂ·log(p_i)
where p_i = weight_i / Î£ weights

Cap enforcement: If H > H_max, sharpen distribution
```

---

## ğŸ”¥ Heat Diffusion on Graphs

### Graph Laplacian Structure

```
Graph:
    1 â”€â”€â”€ 2 â”€â”€â”€ 3
    â”‚     â”‚     â”‚
    4 â”€â”€â”€ 5 â”€â”€â”€ 6

Adjacency Matrix A:
    1  2  3  4  5  6
1 [ 0  1  0  1  0  0 ]
2 [ 1  0  1  0  1  0 ]
3 [ 0  1  0  0  0  1 ]
4 [ 1  0  0  0  1  0 ]
5 [ 0  1  0  1  0  1 ]
6 [ 0  0  1  0  1  0 ]

Degree Matrix D:
    1  2  3  4  5  6
1 [ 2  0  0  0  0  0 ]
2 [ 0  3  0  0  0  0 ]
3 [ 0  0  2  0  0  0 ]
4 [ 0  0  0  2  0  0 ]
5 [ 0  0  0  0  3  0 ]
6 [ 0  0  0  0  0  2 ]

Laplacian L = D - A:
    1  2  3  4  5  6
1 [ 2 -1  0 -1  0  0 ]
2 [-1  3 -1  0 -1  0 ]
3 [ 0 -1  2  0  0 -1 ]
4 [-1  0  0  2 -1  0 ]
5 [ 0 -1  0 -1  3 -1 ]
6 [ 0  0 -1  0 -1  2 ]
```

### Heat Diffusion Process

```
Initial belief at node 1:
x_0 = [1, 0, 0, 0, 0, 0]^T

After diffusion (t=0.5):
y = exp(-0.5Â·L)Â·x_0

Time t=0.0:  [1.00, 0.00, 0.00, 0.00, 0.00, 0.00]
             â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Time t=0.1:  [0.82, 0.09, 0.00, 0.09, 0.00, 0.00]
             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– â–‰

Time t=0.3:  [0.58, 0.21, 0.03, 0.15, 0.02, 0.01]
             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š â–ˆâ–ˆâ– â– â–ˆâ–Œ â–

Time t=0.5:  [0.43, 0.24, 0.07, 0.17, 0.06, 0.03]
             â–ˆâ–ˆâ–ˆâ–ˆâ– â–ˆâ–ˆâ– â–‹ â–ˆâ–‹ â–Œ â–

Time t=1.0:  [0.25, 0.21, 0.12, 0.16, 0.14, 0.12]
             â–ˆâ–ˆâ–Œ â–ˆâ–ˆâ– â–ˆâ– â–ˆâ–Œ â–ˆâ– â–ˆâ–

Belief spreads from node 1 to neighbors over time
```

---

## ğŸ“ˆ Performance Scaling

### Operation Latency vs Dimension

```
Latency (Î¼s)
1000â”‚
    â”‚                                        â•±
 800â”‚                                   â•±â”€â”€â”€â•¯ superpose(n=100)
    â”‚                              â•±â”€â”€â”€â•¯
 600â”‚                         â•±â”€â”€â”€â•¯
    â”‚                    â•±â”€â”€â”€â•¯
 400â”‚               â•±â”€â”€â”€â•¯
    â”‚          â•±â”€â”€â”€â•¯
 200â”‚     â•±â”€â”€â”€â•¯â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ bind/unbind
    â”‚â•±â”€â”€â”€â•¯
   0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Dimension
    512  1024  2048  4096  8192  16384

Linear scaling: O(D) for bind/unbind
Linear scaling: O(nÂ·D) for superpose
```

### Memory Capacity vs Decay Factor

```
Effective Capacity (memories)
1000â”‚
    â”‚                                    â•±
 800â”‚                               â•±â”€â”€â”€â•¯
    â”‚                          â•±â”€â”€â”€â•¯
 600â”‚                     â•±â”€â”€â”€â•¯
    â”‚                â•±â”€â”€â”€â•¯
 400â”‚           â•±â”€â”€â”€â•¯
    â”‚      â•±â”€â”€â”€â•¯
 200â”‚ â•±â”€â”€â”€â•¯
    â”‚â•¯
   0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Decay factor Î·
    0.01  0.02  0.04  0.08  0.16  0.32

Capacity formula: C(Î·, Îµ) = âŒŠlog(Îµ) / log(1-Î·)âŒ‹
Îµ = 0.01 (1% interference threshold)

Î· = 0.08 â†’ C â‰ˆ 55 memories
Î· = 0.04 â†’ C â‰ˆ 113 memories
Î· = 0.02 â†’ C â‰ˆ 228 memories
```

---

## ğŸ¯ Retrieval Accuracy Analysis

### Precision vs Recall Tradeoff

```
Precision
1.0â”‚â—
   â”‚ â•²
0.9â”‚  â—
   â”‚   â•²
0.8â”‚    â—
   â”‚     â•²
0.7â”‚      â—
   â”‚       â•²
0.6â”‚        â—
   â”‚         â•²
0.5â”‚          â—
   â”‚           â•²
0.4â”‚            â—
   â”‚             â•²
0.3â”‚              â—
   â”‚               â•²
0.2â”‚                â—
   â”‚                 â•²
0.1â”‚                  â—
   â”‚
0.0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Recall
   0.0 0.2 0.4 0.6 0.8 1.0

â— Measured points (top_k = 1, 5, 10, 20, 50, 100)

Optimal operating point: top_k â‰ˆ 10
  Precision: 0.87
  Recall: 0.73
  F1-score: 0.79
```

### Score Distribution

```
Frequency
 40â”‚     â—                          True positives (relevant)
    â”‚    â•±â”‚â•²
 30â”‚   â•± â”‚ â•²
    â”‚  â•±  â”‚  â•²
 20â”‚ â•±   â”‚   â•²â—                     False positives (noise)
    â”‚â•±    â”‚    â•²â•²
 10â”‚      â”‚     â•²â—â•²
    â”‚      â”‚      â•² â•²â—
  0â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â•²â”€â”€â•²â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Score
   0.0   0.5      0.8  1.0

Threshold = 0.7 (optimal separation)
  True positive rate: 0.91
  False positive rate: 0.08
```

---

## ğŸ”¬ Mathematical Invariant Verification

### Real-Time Monitoring Dashboard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MATHEMATICAL INVARIANTS STATUS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ âœ“ Spectral Property (â€–H_kâ€–â‰ˆ1)                          â”‚
â”‚   Last 1000 ops: 1000/1000 passed                      â”‚
â”‚   Mean deviation: 0.0003                                â”‚
â”‚                                                         â”‚
â”‚ âœ“ Role Orthogonality (âŸ¨r_i,r_jâŸ©â‰ˆ0)                     â”‚
â”‚   Last 100 pairs: 100/100 passed                       â”‚
â”‚   Mean similarity: 0.0012                               â”‚
â”‚                                                         â”‚
â”‚ âœ“ Binding Correctness (âŸ¨a,bind(a,b)âŸ©â‰ˆ0)                â”‚
â”‚   Last 1000 ops: 998/1000 passed                       â”‚
â”‚   Mean similarity: 0.0087                               â”‚
â”‚                                                         â”‚
â”‚ âœ“ Trace Normalization (â€–M_tâ€–=1)                        â”‚
â”‚   Last 1000 updates: 1000/1000 passed                  â”‚
â”‚   Mean norm: 1.0000                                     â”‚
â”‚                                                         â”‚
â”‚ âœ“ Weight Bounds (w_min â‰¤ w â‰¤ w_max)                    â”‚
â”‚   Clamp events: 3 (0.3% of updates)                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Tenant Isolation Visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MULTI-TENANT ARCHITECTURE               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tenant A                    Tenant B                    Tenant C
   â”‚                           â”‚                           â”‚
   â”‚ R_A (rotation)            â”‚ R_B (rotation)            â”‚ R_C (rotation)
   â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Trace_A â”‚                 â”‚Trace_B â”‚                 â”‚Trace_C â”‚
â”‚  M_A   â”‚                 â”‚  M_B   â”‚                 â”‚  M_C   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚                           â”‚                           â”‚
   â”‚ âŸ¨R_AÂ·k, R_BÂ·kâŸ©â‰ˆ0         â”‚ âŸ¨R_BÂ·k, R_CÂ·kâŸ©â‰ˆ0         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                           â”‚
               â–¼                           â–¼
         Orthogonal                  Orthogonal
         (no interference)           (no interference)

Properties:
âœ“ Each tenant has independent rotation matrix R_i
âœ“ Rotations ensure spectral independence
âœ“ Memories from different tenants don't interfere
âœ“ Queries only retrieve from own tenant's trace
```

---

**This visual guide provides intuitive understanding of SomaBrain's mathematical operations. For rigorous proofs and formal definitions, see the individual topic pages.**

---

**Related:**
- [BHDC Foundations](01-bhdc-foundations.md)
- [Superposition Traces](02-superposition-traces.md)
- [Unified Scoring](03-unified-scoring.md)
- [Adaptive Learning](04-adaptive-learning.md)
